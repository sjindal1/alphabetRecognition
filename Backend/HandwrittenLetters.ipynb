{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load necessary modules\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from scipy import io as matio\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Convolution2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import TensorBoard\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "databalanced = matio.loadmat('emnist-balanced.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45],\n",
       "       [36],\n",
       "       [43],\n",
       "       ...,\n",
       "       [23],\n",
       "       [31],\n",
       "       [ 8]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databalanced['dataset'][0][0][0][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databalanced['dataset'][0][0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height = 28 \n",
    "width = 28\n",
    "max_ele = len(databalanced['dataset'][0][0][0][0][0][1])\n",
    "max_ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databalanced['dataset'][0][0][2][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 48,\n",
       " 1: 49,\n",
       " 2: 50,\n",
       " 3: 51,\n",
       " 4: 52,\n",
       " 5: 53,\n",
       " 6: 54,\n",
       " 7: 55,\n",
       " 8: 56,\n",
       " 9: 57,\n",
       " 10: 65,\n",
       " 11: 66,\n",
       " 12: 67,\n",
       " 13: 68,\n",
       " 14: 69,\n",
       " 15: 70,\n",
       " 16: 71,\n",
       " 17: 72,\n",
       " 18: 73,\n",
       " 19: 74,\n",
       " 20: 75,\n",
       " 21: 76,\n",
       " 22: 77,\n",
       " 23: 78,\n",
       " 24: 79,\n",
       " 25: 80,\n",
       " 26: 81,\n",
       " 27: 82,\n",
       " 28: 83,\n",
       " 29: 84,\n",
       " 30: 85,\n",
       " 31: 86,\n",
       " 32: 87,\n",
       " 33: 88,\n",
       " 34: 89,\n",
       " 35: 90,\n",
       " 36: 97,\n",
       " 37: 98,\n",
       " 38: 100,\n",
       " 39: 101,\n",
       " 40: 102,\n",
       " 41: 103,\n",
       " 42: 104,\n",
       " 43: 110,\n",
       " 44: 113,\n",
       " 45: 114,\n",
       " 46: 116}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = {databalanced['dataset'][0][0][2][i][0]: databalanced['dataset'][0][0][2][i][1] for i in range(len(databalanced['dataset'][0][0][2]))}\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112800) (1, 18800)\n"
     ]
    }
   ],
   "source": [
    "training_images = databalanced['dataset'][0][0][0][0][0][0][:max_ele].reshape(max_ele, height, width, 1)\n",
    "training_labels = databalanced['dataset'][0][0][0][0][0][1][:max_ele]\n",
    "max_ele_test = len(databalanced['dataset'][0][0][1][0][0][1])\n",
    "testing_images = databalanced['dataset'][0][0][1][0][0][0][:max_ele_test].reshape(max_ele_test, height, width, 1)\n",
    "testing_labels = databalanced['dataset'][0][0][1][0][0][1][:max_ele_test]\n",
    "print(training_labels.T.shape, testing_labels.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46    2400\n",
       "11    2400\n",
       "20    2400\n",
       "19    2400\n",
       "18    2400\n",
       "17    2400\n",
       "16    2400\n",
       "15    2400\n",
       "14    2400\n",
       "13    2400\n",
       "12    2400\n",
       "10    2400\n",
       "22    2400\n",
       "9     2400\n",
       "8     2400\n",
       "7     2400\n",
       "6     2400\n",
       "5     2400\n",
       "4     2400\n",
       "3     2400\n",
       "2     2400\n",
       "1     2400\n",
       "21    2400\n",
       "23    2400\n",
       "45    2400\n",
       "35    2400\n",
       "44    2400\n",
       "43    2400\n",
       "42    2400\n",
       "41    2400\n",
       "40    2400\n",
       "39    2400\n",
       "38    2400\n",
       "37    2400\n",
       "36    2400\n",
       "34    2400\n",
       "24    2400\n",
       "33    2400\n",
       "32    2400\n",
       "31    2400\n",
       "30    2400\n",
       "29    2400\n",
       "28    2400\n",
       "27    2400\n",
       "26    2400\n",
       "25    2400\n",
       "0     2400\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = pd.DataFrame(training_labels)\n",
    "Y_train = Y_train[0]\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7bdff2c668>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0kLCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7be0201320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_images[78][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(img):\n",
    "        # Used to rotate images (for some reason they are transposed on read-in)\n",
    "        flipped = np.fliplr(img)\n",
    "        return np.rot90(flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(training_images)):\n",
    "    training_images[i] = rotate(training_images[i])\n",
    "for i in range(len(testing_images)):\n",
    "    testing_images[i] = rotate(testing_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_images = training_images.astype('float32')\n",
    "testing_images = testing_images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_images /= 255\n",
    "testing_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0ERfiAowg8ERfiBoAg/ENT/Ad8oSB4JKQd6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7bdff46080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_images[78][:,:,0])\n",
    "print(Y_train[78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc4mTcRtBaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7bdff06be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testing_images[78][:,:,0])\n",
    "print(testing_labels[78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Hyperparameters\n",
    "    nb_filters = 32 # number of convolutional filters to use\n",
    "    pool_size = (2, 2) # size of pooling area for max pooling\n",
    "    kernel_size = (3, 3) # convolution kernel size\n",
    "    \n",
    "    input_shape = (height, width, 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters,\n",
    "                            kernel_size,\n",
    "                            padding='valid',\n",
    "                            input_shape=input_shape,\n",
    "                            activation='relu'))\n",
    "    model.add(Convolution2D(nb_filters,\n",
    "                            kernel_size,\n",
    "                            activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(mappings), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 47)                24111     \n",
      "=================================================================\n",
      "Total params: 2,393,487\n",
      "Trainable params: 2,393,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(training_labels, len(mappings))\n",
    "y_test = to_categorical(testing_labels, len(mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 47) (18800, 47)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112800 samples, validate on 18800 samples\n",
      "Epoch 1/10\n",
      "112800/112800 [==============================] - 254s 2ms/step - loss: 1.1114 - acc: 0.6706 - val_loss: 0.6755 - val_acc: 0.7835\n",
      "Epoch 2/10\n",
      "112800/112800 [==============================] - 163s 1ms/step - loss: 0.5545 - acc: 0.8175 - val_loss: 0.5471 - val_acc: 0.8207\n",
      "Epoch 3/10\n",
      "112800/112800 [==============================] - 181s 2ms/step - loss: 0.4688 - acc: 0.8411 - val_loss: 0.5132 - val_acc: 0.8332\n",
      "Epoch 4/10\n",
      "112800/112800 [==============================] - 186s 2ms/step - loss: 0.4250 - acc: 0.8544 - val_loss: 0.4794 - val_acc: 0.8389\n",
      "Epoch 5/10\n",
      "112800/112800 [==============================] - 182s 2ms/step - loss: 0.3952 - acc: 0.8626 - val_loss: 0.4578 - val_acc: 0.8454\n",
      "Epoch 6/10\n",
      "112800/112800 [==============================] - 175s 2ms/step - loss: 0.3728 - acc: 0.8679 - val_loss: 0.4553 - val_acc: 0.8503\n",
      "Epoch 7/10\n",
      "112800/112800 [==============================] - 174s 2ms/step - loss: 0.3560 - acc: 0.8735 - val_loss: 0.4533 - val_acc: 0.8502\n",
      "Epoch 8/10\n",
      "112800/112800 [==============================] - 174s 2ms/step - loss: 0.3413 - acc: 0.8778 - val_loss: 0.4473 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "112800/112800 [==============================] - 177s 2ms/step - loss: 0.3268 - acc: 0.8820 - val_loss: 0.4446 - val_acc: 0.8557\n",
      "Epoch 10/10\n",
      "112800/112800 [==============================] - 176s 2ms/step - loss: 0.3162 - acc: 0.8854 - val_loss: 0.4366 - val_acc: 0.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bdf4a0278>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=(testing_images, y_test),\n",
    "              callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18800/18800 [==============================] - 10s 525us/step\n",
      "Test score: 0.439156197411\n",
      "Test accuracy: 0.855957446809\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-180225be25ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bin/model.yaml\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0myaml_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0myaml_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_yaml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bin/model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'save_model' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testing_images, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Offload model to file\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"bin/model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, 'bin/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(testing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction[78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - tensorflowjs\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/win-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/pro/win-64\n",
      "  - https://repo.anaconda.com/pkgs/pro/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflowjs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-72e929a05a48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conda install --yes --prefix {sys.prefix} tensorflowjs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflowjs'"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} tensorflowjs\n",
    "import tensorflowjs as tfjs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
